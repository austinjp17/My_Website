---
title: "Poisson Regression Notes"
author: "Austin Palmer"
date: "2023-04-06"
output: 
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
---

```{r setup, include=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)

```

## **Setup**

### Context

Our goal is to better understand how the number of laws in a state relates to its unique demographic features and political climate. For the former, we'll narrow our focus to the percentage of a state's residents that reside in an urban area.For the latter, we'll utilize historical voting patterns in presidential elections, noting whether a state has consistently voted for the Democratic candidate, consistently voted for the "GOP" Republican candidate, or is a swing state that has flip flopped back and forth.

### Variable Definitions

For each state $i \subset \{1,2,...,50\}$:

-   $Y_i$: Number of anti-discrimination laws

-   $X_{i1}$: Percentage of state residents living in urban areas

-   $2^{nd}$ Predictor: 3 Level Categorical - Democrat, GOP, or Swing

    -   *Democrat serves as baseline. The other levels, GOP and swing, enter the model as indicators*

```{=tex}
\begin{equation*}
  X_{i2} = 
  \begin{cases} 
      1 \text{ GOP} \\
      0 \text{ Otherwise} 
   \end{cases}
\end{equation*}
```
```{=tex}
\begin{equation*}
  X_{i3} = 
  \begin{cases} 
      1 \text{ Swing} \\
      0 \text{ Otherwise} 
   \end{cases}
\end{equation*}
```
## **Normal Approach**

```{r, include=FALSE}
# Load Packages
library(bayesrules)
library(rstanarm)
library(bayesplot)
library(tidyverse)
library(tidybayes)
library(broom.mixed)

# Load data
data(equality_index)
equality <- equality_index
```

Regression Model with a Normal Data Structure:

$Y_i|\beta_0,\beta_1,\beta_2,\beta_3,\sigma \sim N(\mu_i, \sigma^2); \mu_i = \beta_0 + \beta_1X_{i1} + \beta_2X_{i2} + \beta_3X_{i3}$

### Prior Knowledge

-   A typical state with respect to it's urban population and historical voting patterns has $\sim$ 7 laws

-   $\beta_{0c} \sim Normal(7, 1.5^2)$

### Data Exploration

**Descriptive Statistics**

Each year, the Human Rights Campaign releases a "State Equality Index" which monitors the **number of LQBTQ+ rights laws in each state.** Among other state features, the `equality_index` dataset in the `bayesrules` package includes data from the 2019 index.

```{r}
summary(equality$laws)
```

Including all states, the mean number of laws in 13.46, but the median is 5.00, indicating at least one outlier to the high side weighting the mean much higher than the median.

**Frequency Histogram**

```{r}
ggplot(equality, aes(x = laws)) + 
  geom_histogram(color = "white", breaks = seq(0, 160, by = 10)) +
  theme(plot.title = element_text(hjust = 0.5)) +
  ggtitle("Frequency of Law Count") +
  xlab("Number of Laws") +
  ylab("Count")
```

From the histogram we can see that California, at 155 laws, is the high side outlier largely responsible for skewing the mean and median. As a clear outlier, this state will be removed from the analysis

```{r}
#Identify Outlier
equality %>%
  filter(laws == max(laws))

#Remove Outlier
equality <- equality %>%
  filter(state != "california")
```

**Scatterplot**

```{r}
ggplot(equality, aes(y = laws, x = percent_urban, color = historical)) +
  geom_point()
```

Analyzing a scatter plot of the number of LGBTQ+ `laws` vs `percent_urban` population and `historical` voting patterns, we can see that historically democratic states and states with greater urban populations tend to have more laws in place. Historically GOP voting states tend to have far less laws, generally less than 10, and have a significantly higher rural population.

### Model Building

We know the typical number of laws to be centered around 7. We utilize weakly informative priors for the other parameters.

```{r Normal Model Build, results=FALSE}
b0 <- normal(7,1.5)
b1 <- normal(0, 2.5, autoscale = TRUE)
sigma <- exponential(1, autoscale = TRUE)
equality_normal_sim <- stan_glm(laws~percent_urban + historical,
                                data=equality, family = gaussian,
                                prior_intercept = normal(7,1.5),
                                prior = normal(0, 2.5, autoscale = TRUE),
                                prior_aux = sigma,
                                chains=4, iter=5000*2, seed=84735)
```

```{r Normal Model Check}
pp_check(equality_normal_sim, plotfun = "hist", nreps=5) +
  geom_vline(xintercept = 0) +
  xlab("laws")
```

In a quick posterior predictive check, we compare a histogram of the observed frequency of anti-discrimination laws to five posterior simulated datasets. A histogram is more appropriate than a density plot in the case because our response variable is a non-negative count. The predicted distributions don't compare well to the observed. This is because the observed data is right skewed, not normal. In contrast, the simulated datasets from the posterior Normal Regression model are roughly symmetric and assume that it is common for states to have a negative number of anti-discrimination laws.

## **Poisson Approach**

### Why Poisson?

A Poisson model is appropriate for modeling discrete counts of events (here anti-discrimination laws) that happen in a fixed interval of space or time (here states) and that, *theoretically*, have no upper bound. The Poisson is especially handy in cases like ours in which counts are right-skewed, and thus can't be reasonably approximated by a Normal model.

### Specifying the Data Model

Moving forward, lets assume a **Poisson data model** for the number of anti-discrimination laws in each state $i (Y_i)$ where the *rate* of laws $\lambda_i$ depends upon demographic and voting trends ($X_{i1}, X_{i2}, X_{i3}$):

$$ Y_i|\lambda_i \sim Pois(\lambda_i)$$

Under the Poisson structure, the *expected/average* number of laws, $Y_i$, in states with similar predictor values $X$ is captured by $\lambda_i$:

$$ E(Y_i|\lambda_i) = \lambda_i $$

If we were to proceed as in Normal Regression, we might assume the average number of laws is linear combination of our predictors, $\lambda_i = \beta_0 + \beta_1X_{i1} + \beta_2X_{i2} + \beta_3X_{i3}$. This assumption is illustrated by by the lines below, one per historical voting trend.

INSERT ILLUSTRATION

When we assume that $\lambda_i$ can be expressed by a linear combination of X predictors, the model of $\lambda_i$ spans both positive and negative values, suggesting states can have a negative number of anti-discrimination laws. That's nonsensical. Like the number of laws, a Poisson rate $\lambda_i$, must be *positive*.

To avoid this violation, it is common to use a **log link function**. Meaning, we'll assume that $log(\lambda_i)$, which does span both positive and negative values, is a linear combo of the X predictors.

$$Y_i|\lambda_i \sim Pois(\lambda_i)\text{ st: } log(\lambda_i) = \beta_0 + \beta_1X_{i1} + \beta_2X_{i2} + \beta_3X_{i3}$$

Interpreting logged number of laws isn't so easy. Instead we can transform the model relationship off the log scale by using the relationship: $log(\lambda) = a \equiv \lambda = e^a$

$$Y_i|\lambda_i \sim Pois(\lambda_i)\text{ st: } \lambda_i = e^{\beta_0 + \beta_1X_{i1} + \beta_2X_{i2} + \beta_3X_{i3}}$$

### Interpreting Poisson Regression Coefficients

Consider the two equivalent formulations of the Poisson regression model: $Y|\beta_0,\beta_1,...,\beta_p \sim Pois(\lambda)$ st:

$$log(\lambda_i) = \beta_0 + \beta_1X_{1} + \beta_2X_{2} +... \beta_pX_{p}$$

$$\lambda_i = e^{\beta_0 + \beta_1X_{1} + \beta_2X_{2} +... \beta_pX_{p}}$$ **Interpreting** $\beta_0$

When $X_1, X_2,...,X_p$ are all 0, $\beta_0$ is the logged baseline $Y$ value and $e^{\beta_0}$ is the baseline $Y$ value.

\*\*Interpreting $\beta_1, \beta_2,...,\beta_p$

When we control for all other predictors and increase $X_1$ by 1:

-   $\beta_1$ is the logged average $Y$ value

-   $e^{\beta_1}$ is the multiplicative change in the (unlogged) baseline $Y$ value.

$$\beta_1 = log(\lambda_x+1) - log(\lambda_x) \hspace{10mm} \text{and} \hspace{10mm} e^{\beta_1} = \frac{\lambda_{x+1}}{\lambda_x}$$

### Interpretations Applied

The curves are defined by:

$$ log(\lambda_i) = 2 + 0.03X_{i1} - 1.1X_{i2} - 0.6X_{i3}$$

$$\lambda = e^{2 + 0.03X_{i1} - 1.1X_{i2} - 0.6X_{i3}}$$ **Intercept Interpretation**

$\beta_0 = 2$: This intercept reflects the trends in anti-discrimination laws in historically Democratic states with 0 urban population ($X_{i1}, X_{i2}, X_{i3} = 0$). Meaning we can expect the logged number of laws in such states to be 2. More meaningfully, we expect historically Democratic states with 0 urban population to have $\sim$ 7.4 anti-discrimination laws

$$e^{\beta_0} = e^2 = 7.389$$ $\beta_1$ interpretation

$\beta_1 = 0.03$: No matter a state's historical voting trends, we expect *logged* number of laws in states to increase by 0.03 for every extra percentage point in urban population. If the urban population of one state is 1 percent greater than another state, we'd expect it to have 1.03 *times*, or 3% more the number of anti-discrimination laws.

$$e^{\beta_1} = e^{0.03} = 1.03$$

Though the model curves don't increase by the same *absolute* amount for each `percent_urban` increment, they do increase by the same *percentage*. Thus, $e^{\beta_1}$ measures the nonlinear *percentage* or *multiplicative* increase in the average number of laws with urban percentage.

$\beta_2$ interpretation

$\beta_2 = -1.1$: When interpreting a coefficient for a categorical indicator, we must do so relative to the reference category, here Democrat leaning states. Thus, at any urban percentage, we'd expect the *logged* number of laws to be 1.1 lower in historically GOP states than Democrat states. Importantly, the difference isn't constant - the gap in number of laws widens as urban percentage increases. Thus, at any urban percentage level, we'd expect a historically GOP state to have $\frac{1}{3}$ as many anti-discrimination laws as a historically Democrat state:

$$e^{\beta_2} = e^{-1.1} = 0.333$$

### Assumptions

Consider the Bayesian Poisson regression model with $Y_i|\beta_0,\beta_1,...,\beta_p \sim Pois(\lambda_i)$ st: $$log(\lambda_i) = \beta_0 + \beta_1X_{i1} + ... + \beta_pX_{ip}$$

The appropriateness of this model depends upon the following assumptions:

-   **Structure of the Data**

    Conditioned on predictors $X$, the observed data $Y_i$ on case $i$ is **independent** of the observed data on any other vase $j$

-   **Structure of variable** $Y$

    Response variable $Y$ has a Poisson structure, i.e., is a discrete **count** of events that happen in a fixed interval of space or time

-   **Structure of the relationship**

    The *logged* average of $Y$ can be written as a **linear combination** of the predictors,

    $log(\lambda_i) = \beta_0 + \beta_1X_{i1} + \beta_2X_{i2} + \beta_3X_{i3}$

-   **Structure of the variability in Y**

    A Poisson random variable $Y$ with rate $\lambda$ has equal mean and variance, $E(Y) = Var(Y) = \lambda$. Thus, conditioned on predictors $X$, the *typical* value of $Y$ should be roughly equivalent to the *variability* in $Y$. As such, the variability in $Y$ increases as its mean increases.

### Specifying The Priors

To complete our Bayesian model, we must express our prior understanding of regression coefficients. Since these coefficients can take on any real value, it's again reasonable to utilize Normal priors. Further, as was the case for our Normal regression, we'll assume these priors are **independent**.

The complete representation of our **Poisson regression model** of $Y_i$ is as follows:

$$\text{data:}\hspace{5mm} Y_i|\beta_0,\beta_1,\beta_2,\beta_3 \sim Pois(\lambda_i) \hspace{5mm}\text{st:}\hspace{5mm} log(\lambda_i) = \beta_0 + \beta_{i1} + \beta_2X_{i2} + \beta_3X_{i3}$$ $$\text{priors: }\\ \beta_{0c} \sim Normal(2, 0.5^2) \\ \beta_1 \sim Normal(0, 0.17^2) \\ \beta_2 \sim Normal(0, 4.97^2) \\ \beta_3 \sim Normal(0, 5.60^2) $$

First, consider the prior for the centered intercept $\beta_{0c}$. Recall our prior assumption that the average number of laws in a "typical" state is around 7. As such, we set thhe Normal prior mean for \$\beta\_{0c} to 2 on the *log* scale. Beyond this baseline, we again employ weakly informative default priors, tuned by `stan_glm()` below.

To examine if these combined priors accurately reflect our uncertain understanding of state laws, we'll simulate 20,000 draws from the prior models of ($\beta_0, \beta_1, \beta_2, \beta_3$). To this end, we can run the same `stan_glm()` used to simulate the posterior with two new arguments: `prior_PD = TRUE`, which specifies that we wish to simulate the *prior*, and `family = poisson`, to indicate we're using a Poisson data model.

```{r Poisson Model Build Prior, results=FALSE}
b0 <- normal(2,0.5)
b1 <- normal(0, 2.5, autoscale = TRUE)

equality_model_prior <- stan_glm(laws~percent_urban + historical,
                                 data = equality,
                                 family = poisson,
                                 prior_intercept = normal(2,0.5),
                                 prior = normal(0, 2.5, autoscale = TRUE),
                                 chains = 4, iter = 5000*2, seed = 84735,
                                 prior_PD = TRUE)
```

A call to `prior_summary` confirms the specification of our weakly informative priors

```{r}
prior_summary(equality_model_prior)
```

Next we plot 100 prior plausible models, \$e\^{\beta\_0 + \beta\_1x_1 + \beta\_2x_2 + \beta\_3x_3}.

```{r, warning=FALSE}
equality %>%
  add_fitted_draws(equality_model_prior, n=100) %>%
  ggplot(aes(x = percent_urban, y = laws, color = historical)) + 
  geom_line(aes(y = .value, group = paste(historical, .draw))) +
  ylim(0, 100)
```

The mess of curves reflects our prior uncertainty. The lines are all over the map, indicating that the number of laws may increase *or* decrease with urban population and might or might not differ by historical voting trends. We don't really know...

### Simulating the Posterior

```{r Poisson Posterior Build, results=FALSE}
equality_model <- update(equality_model_prior, prior_PD = FALSE)
```

MCMC trace, density, and autocorrelation plots confirm that our simulation has stabilized:

```{r}
mcmc_trace(equality_model)
mcmc_dens_overlay(equality_model)
mcmc_acf(equality_model)
```

A quick posterior predictive check also confirms we're now on the right track:

```{r}
set.seed(1)
pp_check(equality_model, plotfun = "hist", nreps = 5) + 
  xlab("laws")
```

Histograms of just five posterior simulations of state law data exhibit similar skew, range, and trends as the observed data.

```{r}
pp_check(equality_model)+
  xlab("laws")
```

Comparing 50 plausibilities, we can see that the simulations aren't perfect but capture the observed data features reasonably well.

### Interpreting The Posterior

With the reassurance that our model isn't too wrong, lets dig into the posterior results, beginning with the big picture. The 50 posterior plausible models below provide insight into our overall understanding of anti-discrimination laws.

```{r warning=FALSE}
equality %>%
  add_fitted_draws(equality_model, n = 50) %>%
  ggplot(aes(x = percent_urban, y = laws, color = historical)) +
    geom_line(aes(y = .value, group = paste(historical, .draw)), 
              alpha = .1) +
    geom_point(data = equality, size = 0.1)
```

Unlike the prior plausibilities, the trends are clear. At any urban population level, `dem` states tend to have the most anti-discrimination laws and `gop` states the fewest. Further, the number of laws in a state tend to increase with urban percentage. To get more in detail, we can examine the posterior models for the regression paramaters:

**Parameter Estimates**

```{r}
tidy(equality_model, conf.int = TRUE, conf.level = 0.80)
```

All estimate confidence ranges don't contain zero. Thus, the posterior median relationship of a state's number of anti-discrimination laws with its urban population and historical voting trends can be described by:

$$ log(\lambda_i) = 1.71 + 0.0164X_{i1} - 1.52X_{i2} - 0.61X_{i3} $$

$$ \lambda_i = e^{1.71 + 0.0164X_{i1} - 1.52X_{i2} - 0.61X_{i3}} $$

$\beta_1$ interpretation

Consider the `percent_urban` coefficient $\beta_1$, which has a posterior median of roughly 0.0164. Then, when controlling for `historical` voting trends, we expect the *logged* number of anti-discrimination laws in states to increase by 0.0164 for every extra percentage point in urban population. More meaningfully, if the urban population in one state is 1 percent higher than another, we'd expect it to have 1.0165 *times* the number of, or 1.65% more, anti-discrimination laws:

$$ e^{0.0164} = 1.165$$

Or, if the urban population in one state in 25% greater than another, we'd expect it to have roughly *one and a half* times the number of, or 51% more, anti-discrimination laws ($e^{25*0.0164} = 1.5068$).

### Posterior Prediction

**Prediction using `posterior_predict()` Shortcut**

To explore how the general Poisson model plays out in individual states, consider Minnesota, a historically `dem` state with 73.3% of residents living in urban areas, and 4 anti-discrimination laws:

```{r}
equality %>%
  filter(state == "minnesota")
```

Based on the state's demographics and political leanings, we can approximate a posterior predictive model for its number of anti-discrimination laws. Importantly, reflecting the Poisson data structure of our model, the 20,000 simulated posterior predictions are *counts*:

```{r}
#Calculate Posterior Predictions
set.seed(84735)
mn_prediction <- posterior_predict(
  equality_model, newdata=data.frame(percent_urban = 73.3,
                                     historical = "dem"))
mcmc_hist(mn_prediction, binwidth = 1) +
  geom_vline(xintercept = 4) +
  xlab("Predicted number of laws in Minnesota")
```

The resulting posterior predictive model anticipates that Minnesota has between 10 and 30 anti-discrimination laws, a range that falls far above the observed value of 4. This discrepancy reveals that a state's demographics and political leanings, and thus our Poisson model, don't tell the full story behind its anti-discrimination laws. It also reveals that Minnesota has an unusually small number of anti-discrimination laws for a state with such a high urban population and historically Democratic voting trends.

**Long Way Check**

Instead of using `posterior_predict()`, we could directly predict the number of laws in Minnesota from each of the 20,000 plausibilities. To this end we:

1)  Calculate the logged average number of laws in states like Minnesota, with a 73.3% urban percentage and historically Democrat voting patterns:

$$log(\lambda^i) = \beta_0^i + \beta_1^i * 73.3 + \beta_2^i * 0 + \beta_3^i * 0$$

2)  Transform $log(\lambda^i)$ to obtain unlogged average of number of laws in states like Minnesota

3)  Simulate a Pois($\lambda^i$) outcome for the number of laws in Minnesota, \$Y\^i\_{new}, using `rpois()`

```{r}
set.seed(84735)
as.data.frame(equality_model) %>%
  mutate(log_lambda = `(Intercept)` + percent_urban*73.3 +
           historicalgop*0 + historicalswing*0,
         lambda = exp(log_lambda),
         y_new = rpois(20000, lambda = lambda)) %>%
  ggplot(aes(x = y_new)) +
    stat_count()
```

The results matches that of `posterior_predict()`, so we can be confident in the stability of the prediction.

### Model Evaluation

Lets evaluate the quality of our Poisson regression model of anti-discrimination laws through 3 questions:

1)  **How fair is our model?**

Though we don't believe there to be bias in the data collection process, it would be unfair to use the general state-level trends revealed in our analysis to make assumptions about individuals based on their voting behavior or where they live. Further, an analysis of the number of state laws don't reflect the quality of those laws.

2)  **How wrong is our model?**

Our \``pp_check()` earlier demonstrated that our Poisson regression assumptions are reasonable

3)  **How accurate are our model predictions?**

As we did or the state of Minnesota, we can examine the posterior predictive models for each of the 49 states in our dataset. The plot below illustrates the posterior predictive credible intervals for the number of laws in each state alongside the actual observed data.

```{r}
  #Simulate posterior predictive models for each state
  set.seed(84735)
  poisson_predictions <- posterior_predict(equality_model, newdata = equality)
  
  # Plot the posterior predictive models for each state
  ppc_intervals_grouped(equality$laws, yrep = poisson_predictions,
                        x = equality$percent_urban,
                        group = equality$historical,
                        prob = 0.5, prob_outer = 0.95,
                        facet_args = list(scales = "fixed"))
  
  
```

Overall our model does better at anticipating the number of laws in `gop` states than in `dem` or `swing` states - more of the observed `gop` data points fall within the credible interval bounds. As exhibited by the narrower intervals, we also have more posterior certainty about the `gop` states where the number of laws tends to be consistently small.

We can formalize our observations above using `prediction_summary()`.

```{r}
prediction_summary(model = equality_model, data = equality)
```

Across the 49 states in our study, the observed numbers of anti-discrimination laws tend to fall only 3.4 laws, or 1.3 posterior standard deviations, from their posterior mean predictions. Given the number of state laws, from 1 to 38, a typical prediction error of 3.4 seems pretty good! Countering this positive with a negative, the observed number of laws for only roughly 78% of the states fall within their corresponding 95% posterior prediction interval. This means that our posterior predictive models "missed" or didn't anticipate the number of laws in 22%, of 11, of the 49 states.

For due diligence, we also calculate the *cross-validated* posterior predictive accuracy in apply this model to a "new" set of 50 states, or the *same* set of 50 states under the recognition that our current data is just a andom snapshot in time.

```{r Cross Validating Poisson}
#Cross-Validation
set.seed(84735)
poisson_cv <- prediction_summary_cv(model = equality_model,
                                    data = equality, k=10)
poisson_cv
```

In this case the results are similar, suggesting our model is **not** overfit to our sample data - we expect it to perform just as well at predicting "new" states.

